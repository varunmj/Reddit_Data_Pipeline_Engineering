[2024-08-09T00:00:02.555+0000] {processor.py:161} INFO - Started process (PID=389) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:00:02.563+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:00:02.570+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:00:02.569+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:00:02.669+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:00:02.670+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:00:02.717+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:00:02.718+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:00:02.891+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:00:03.223+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:00:03.223+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:00:03.383+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:00:03.382+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:00:03.448+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.900 seconds
[2024-08-09T00:00:33.959+0000] {processor.py:161} INFO - Started process (PID=391) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:00:33.962+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:00:33.967+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:00:33.966+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:00:34.104+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:00:34.105+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:00:34.139+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:00:34.139+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:00:34.270+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:00:34.306+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:00:34.305+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:00:34.357+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:00:34.357+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:00:34.376+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.432 seconds
[2024-08-09T00:01:04.613+0000] {processor.py:161} INFO - Started process (PID=393) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:01:04.616+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:01:04.620+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:01:04.620+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:01:04.753+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:01:04.753+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:01:04.792+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:01:04.792+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:01:04.920+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:01:04.956+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:01:04.956+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:01:04.993+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:01:04.993+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:01:05.020+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.420 seconds
[2024-08-09T00:01:35.159+0000] {processor.py:161} INFO - Started process (PID=395) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:01:35.164+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:01:35.175+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:01:35.174+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:01:35.309+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:01:35.310+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:01:35.347+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:01:35.348+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:01:35.477+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:01:35.509+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:01:35.509+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:01:35.529+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:01:35.529+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:01:35.538+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.392 seconds
[2024-08-09T00:02:05.858+0000] {processor.py:161} INFO - Started process (PID=397) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:02:05.861+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:02:05.869+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:02:05.868+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:02:06.033+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:02:06.033+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:02:06.066+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:02:06.066+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:02:06.213+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:02:06.241+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:02:06.241+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:02:06.254+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:02:06.254+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:02:06.269+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.432 seconds
[2024-08-09T00:02:36.657+0000] {processor.py:161} INFO - Started process (PID=399) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:02:36.660+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:02:36.668+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:02:36.667+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:02:36.810+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:02:36.810+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:02:36.842+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:02:36.842+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:02:36.955+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:02:37.009+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:02:37.008+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:02:37.048+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:02:37.048+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:02:37.066+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.431 seconds
[2024-08-09T00:03:07.754+0000] {processor.py:161} INFO - Started process (PID=401) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:03:07.755+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:03:07.769+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:03:07.767+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:03:07.897+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:03:07.897+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:03:07.940+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:03:07.940+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:03:08.060+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:03:08.085+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:03:08.084+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:03:08.107+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:03:08.107+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:03:08.116+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.374 seconds
[2024-08-09T00:03:38.407+0000] {processor.py:161} INFO - Started process (PID=403) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:03:38.408+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:03:38.421+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:03:38.418+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:03:38.551+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:03:38.552+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:03:38.585+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:03:38.585+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:03:38.712+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:03:38.737+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:03:38.737+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:03:38.750+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:03:38.750+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:03:38.758+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.365 seconds
[2024-08-09T00:04:08.988+0000] {processor.py:161} INFO - Started process (PID=405) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:04:08.990+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:04:09.021+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:04:09.019+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:04:09.153+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:04:09.154+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:04:09.186+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:04:09.186+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:04:09.306+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:04:09.342+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:04:09.341+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:04:09.355+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:04:09.355+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:04:09.363+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.399 seconds
[2024-08-09T00:04:39.587+0000] {processor.py:161} INFO - Started process (PID=407) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:04:39.588+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:04:39.593+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:04:39.592+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:04:39.723+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:04:39.724+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:04:39.755+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:04:39.755+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:04:39.869+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:04:39.894+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:04:39.894+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:04:39.917+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:04:39.917+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:04:39.926+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.351 seconds
[2024-08-09T00:05:10.097+0000] {processor.py:161} INFO - Started process (PID=409) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:05:10.098+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:05:10.104+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:05:10.102+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:05:10.253+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:05:10.253+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:05:10.287+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:05:10.288+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:05:10.410+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:05:10.435+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:05:10.435+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:05:10.463+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:05:10.463+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:05:10.472+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.391 seconds
[2024-08-09T00:05:40.876+0000] {processor.py:161} INFO - Started process (PID=411) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:05:40.877+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:05:40.881+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:05:40.880+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:05:41.046+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:05:41.046+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:05:41.078+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:05:41.078+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:05:41.223+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:05:41.257+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:05:41.257+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:05:41.270+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:05:41.270+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:05:41.278+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.416 seconds
[2024-08-09T00:06:11.721+0000] {processor.py:161} INFO - Started process (PID=413) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:06:11.723+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:06:11.726+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:06:11.726+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:06:11.863+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:06:11.863+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:06:11.905+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:06:11.905+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:06:12.039+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:06:12.066+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:06:12.066+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:06:12.091+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:06:12.091+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:06:12.118+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.416 seconds
[2024-08-09T00:06:42.595+0000] {processor.py:161} INFO - Started process (PID=415) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:06:42.596+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:06:42.600+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:06:42.600+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:06:42.707+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:06:42.707+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:06:42.745+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:06:42.745+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:06:42.857+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:06:42.889+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:06:42.889+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:06:42.930+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:06:42.930+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:06:42.947+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.365 seconds
[2024-08-09T00:07:13.596+0000] {processor.py:161} INFO - Started process (PID=417) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:07:13.601+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:07:13.609+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:07:13.608+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:07:13.761+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:07:13.761+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:07:13.803+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:07:13.803+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:07:13.918+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:07:13.941+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:07:13.941+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:07:13.954+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:07:13.954+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:07:13.962+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.388 seconds
[2024-08-09T00:07:44.416+0000] {processor.py:161} INFO - Started process (PID=419) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:07:44.420+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:07:44.424+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:07:44.424+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:07:44.561+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:07:44.561+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:07:44.591+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:07:44.591+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:07:44.712+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:07:44.734+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:07:44.734+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:07:44.747+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:07:44.747+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:07:44.756+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.380 seconds
[2024-08-09T00:08:15.060+0000] {processor.py:161} INFO - Started process (PID=421) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:08:15.063+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:08:15.071+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:08:15.070+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:08:15.187+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:08:15.187+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:08:15.216+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:08:15.216+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:08:15.347+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:08:15.380+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:08:15.380+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:08:15.394+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:08:15.394+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:08:15.403+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.367 seconds
[2024-08-09T00:08:45.890+0000] {processor.py:161} INFO - Started process (PID=423) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:08:45.893+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:08:45.898+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:08:45.897+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:08:46.179+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:08:46.180+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:08:46.213+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:08:46.213+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:08:46.335+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:08:46.356+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:08:46.356+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:08:46.376+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:08:46.375+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:08:46.385+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.522 seconds
[2024-08-09T00:09:16.877+0000] {processor.py:161} INFO - Started process (PID=425) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:09:16.878+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:09:16.882+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:09:16.882+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:09:17.014+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:09:17.014+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:09:17.054+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:09:17.055+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:09:17.165+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:09:17.198+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:09:17.197+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:09:17.218+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:09:17.218+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:09:17.228+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.370 seconds
[2024-08-09T00:09:47.338+0000] {processor.py:161} INFO - Started process (PID=427) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:09:47.342+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:09:47.357+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:09:47.350+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:09:47.486+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:09:47.487+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:09:47.517+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:09:47.518+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:09:47.634+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:09:47.663+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:09:47.663+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:09:47.677+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:09:47.677+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:09:47.685+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.373 seconds
[2024-08-09T00:10:18.206+0000] {processor.py:161} INFO - Started process (PID=429) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:10:18.207+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:10:18.212+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:10:18.211+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:10:18.333+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:10:18.333+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:10:18.363+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:10:18.363+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:10:18.480+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:10:18.503+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:10:18.503+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:10:18.515+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:10:18.515+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:10:18.524+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.354 seconds
[2024-08-09T00:10:48.888+0000] {processor.py:161} INFO - Started process (PID=431) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:10:48.889+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:10:48.894+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:10:48.894+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:10:49.048+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:10:49.049+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:10:49.079+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:10:49.079+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:10:49.200+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:10:49.221+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:10:49.221+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:10:49.233+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:10:49.233+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:10:49.241+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.368 seconds
[2024-08-09T00:11:19.399+0000] {processor.py:161} INFO - Started process (PID=433) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:11:19.400+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:11:19.405+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:11:19.404+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:11:19.526+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:11:19.526+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:11:19.567+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:11:19.567+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:11:19.675+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:11:19.709+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:11:19.709+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:11:19.722+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:11:19.722+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:11:19.730+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.365 seconds
[2024-08-09T00:11:49.920+0000] {processor.py:161} INFO - Started process (PID=435) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:11:49.923+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:11:49.928+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:11:49.928+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:11:50.090+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:11:50.091+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:11:50.123+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:11:50.123+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:11:50.238+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:11:50.262+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:11:50.262+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:11:50.275+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:11:50.275+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:11:50.283+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.386 seconds
[2024-08-09T00:12:20.524+0000] {processor.py:161} INFO - Started process (PID=437) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:12:20.528+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:12:20.532+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:12:20.531+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:12:20.674+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:12:20.674+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:12:20.709+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:12:20.709+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:12:20.826+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:12:20.855+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:12:20.855+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:12:20.868+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:12:20.868+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:12:20.876+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.390 seconds
[2024-08-09T00:12:51.199+0000] {processor.py:161} INFO - Started process (PID=439) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:12:51.201+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:12:51.205+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:12:51.205+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:12:51.329+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:12:51.330+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:12:51.400+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:12:51.400+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:12:51.544+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:12:51.566+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:12:51.566+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:12:51.585+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:12:51.584+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:12:51.600+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.440 seconds
[2024-08-09T00:13:22.024+0000] {processor.py:161} INFO - Started process (PID=441) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:13:22.026+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:13:22.030+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:13:22.030+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:13:22.171+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:13:22.171+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:13:22.206+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:13:22.206+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:13:22.321+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:13:22.344+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:13:22.343+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:13:22.359+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:13:22.358+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:13:22.373+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.362 seconds
[2024-08-09T00:13:52.490+0000] {processor.py:161} INFO - Started process (PID=443) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:13:52.494+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:13:52.499+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:13:52.498+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:13:52.632+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:13:52.632+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:13:52.670+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:13:52.670+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:13:52.805+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:13:52.827+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:13:52.827+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:13:52.839+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:13:52.839+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:13:52.847+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.391 seconds
[2024-08-09T00:14:23.171+0000] {processor.py:161} INFO - Started process (PID=445) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:14:23.173+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:14:23.178+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:14:23.177+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:14:23.297+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:14:23.298+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:14:23.362+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:14:23.362+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:14:23.499+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:14:23.531+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:14:23.530+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:14:23.544+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:14:23.544+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:14:23.552+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.449 seconds
[2024-08-09T00:14:53.665+0000] {processor.py:161} INFO - Started process (PID=447) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:14:53.668+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:14:53.673+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:14:53.672+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:14:53.815+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:14:53.816+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:14:53.863+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:14:53.863+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:14:54.065+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:14:54.095+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:14:54.095+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:14:54.135+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:14:54.135+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:14:54.144+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.512 seconds
[2024-08-09T00:15:24.396+0000] {processor.py:161} INFO - Started process (PID=449) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:15:24.397+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:15:24.402+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:15:24.401+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:15:24.533+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:15:24.534+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:15:24.571+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:15:24.571+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:15:24.724+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:15:24.758+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:15:24.758+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:15:24.771+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:15:24.771+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:15:24.780+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.416 seconds
[2024-08-09T00:15:55.080+0000] {processor.py:161} INFO - Started process (PID=451) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:15:55.082+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:15:55.087+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:15:55.086+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:15:55.225+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:15:55.226+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:15:55.270+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:15:55.270+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:15:55.390+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:15:55.415+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:15:55.414+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:15:55.429+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:15:55.429+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:15:55.444+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.398 seconds
[2024-08-09T00:16:25.565+0000] {processor.py:161} INFO - Started process (PID=453) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:16:25.567+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:16:25.572+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:16:25.571+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:16:25.723+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:16:25.724+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:16:25.763+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:16:25.763+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:16:25.934+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:16:25.958+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:16:25.957+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:16:25.993+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:16:25.993+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:16:26.003+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.452 seconds
[2024-08-09T00:16:56.588+0000] {processor.py:161} INFO - Started process (PID=455) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:16:56.591+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:16:56.595+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:16:56.595+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:16:56.739+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:16:56.739+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:16:56.776+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:16:56.777+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:16:56.925+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:16:56.970+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:16:56.970+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:16:56.986+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:16:56.985+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:16:56.994+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.418 seconds
[2024-08-09T00:17:27.498+0000] {processor.py:161} INFO - Started process (PID=457) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:17:27.499+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:17:27.504+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:17:27.503+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:17:27.634+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:17:27.634+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:17:27.670+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:17:27.670+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:17:27.824+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:17:27.852+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:17:27.852+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:17:27.880+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:17:27.880+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:17:27.891+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.430 seconds
[2024-08-09T00:17:58.523+0000] {processor.py:161} INFO - Started process (PID=459) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:17:58.524+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:17:58.528+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:17:58.527+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:17:58.662+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:17:58.663+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:17:58.706+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:17:58.706+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:17:58.839+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:17:58.877+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:17:58.877+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:17:58.891+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:17:58.891+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:17:58.900+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.389 seconds
[2024-08-09T00:18:29.388+0000] {processor.py:161} INFO - Started process (PID=461) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:18:29.389+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:18:29.393+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:18:29.393+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:18:29.512+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:18:29.512+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:18:29.560+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:18:29.560+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:18:29.675+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:18:29.700+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:18:29.700+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:18:29.714+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:18:29.714+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:18:29.722+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.350 seconds
[2024-08-09T00:19:00.255+0000] {processor.py:161} INFO - Started process (PID=463) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:19:00.257+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:19:00.261+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:19:00.260+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:19:00.386+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:19:00.386+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:19:00.422+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:19:00.423+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:19:00.602+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:19:00.637+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:19:00.637+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:19:00.651+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:19:00.651+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:19:00.660+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.428 seconds
[2024-08-09T00:19:31.054+0000] {processor.py:161} INFO - Started process (PID=465) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:19:31.055+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:19:31.060+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:19:31.059+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:19:31.203+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:19:31.204+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:19:31.240+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:19:31.240+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:19:31.355+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:19:31.389+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:19:31.389+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:19:31.402+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:19:31.402+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:19:31.411+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.370 seconds
[2024-08-09T00:20:01.916+0000] {processor.py:161} INFO - Started process (PID=467) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:20:01.918+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:20:01.923+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:20:01.922+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:20:02.070+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:20:02.070+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:20:02.107+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:20:02.107+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:20:02.285+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:20:02.318+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:20:02.318+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:20:02.339+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:20:02.339+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:20:02.348+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.467 seconds
[2024-08-09T00:20:32.761+0000] {processor.py:161} INFO - Started process (PID=469) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:20:32.763+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:20:32.767+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:20:32.767+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:20:32.896+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:20:32.897+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:20:32.932+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:20:32.932+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:20:33.060+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:20:33.101+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:20:33.100+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:20:33.115+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:20:33.115+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:20:33.124+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.376 seconds
[2024-08-09T00:21:03.634+0000] {processor.py:161} INFO - Started process (PID=471) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:21:03.636+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:21:03.641+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:21:03.640+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:21:03.782+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:21:03.782+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:21:03.819+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:21:03.819+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:21:03.946+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:21:03.972+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:21:03.972+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:21:03.985+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:21:03.985+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:21:03.994+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.394 seconds
[2024-08-09T00:21:34.401+0000] {processor.py:161} INFO - Started process (PID=473) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:21:34.406+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:21:34.419+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:21:34.419+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:21:34.538+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:21:34.538+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:21:34.586+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:21:34.587+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:21:34.771+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:21:34.810+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:21:34.809+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:21:34.823+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:21:34.823+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:21:34.831+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.443 seconds
[2024-08-09T00:22:05.304+0000] {processor.py:161} INFO - Started process (PID=475) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:22:05.307+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:22:05.311+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:22:05.310+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:22:05.447+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:22:05.447+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:22:05.484+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:22:05.484+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:22:05.607+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:22:05.644+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:22:05.644+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:22:05.658+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:22:05.658+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:22:05.667+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.391 seconds
[2024-08-09T00:22:35.807+0000] {processor.py:161} INFO - Started process (PID=477) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:22:35.809+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:22:35.814+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:22:35.813+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:22:35.970+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:22:35.971+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:22:36.026+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:22:36.026+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:22:36.161+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:22:36.190+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:22:36.190+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:22:36.204+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:22:36.204+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:22:36.212+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.437 seconds
[2024-08-09T00:23:06.720+0000] {processor.py:161} INFO - Started process (PID=479) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:23:06.722+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:23:06.726+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:23:06.726+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:23:06.858+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:23:06.859+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:23:06.904+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:23:06.905+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:23:07.104+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:23:07.146+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:23:07.146+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:23:07.161+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:23:07.160+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:23:07.169+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.459 seconds
[2024-08-09T00:23:37.622+0000] {processor.py:161} INFO - Started process (PID=481) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:23:37.624+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:23:37.629+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:23:37.628+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:23:37.765+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:23:37.766+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:23:37.802+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:23:37.803+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:23:37.934+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:23:38.010+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:23:38.010+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:23:38.026+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:23:38.026+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:23:38.036+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.429 seconds
[2024-08-09T00:24:08.554+0000] {processor.py:161} INFO - Started process (PID=483) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:24:08.557+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:24:08.562+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:24:08.561+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:24:08.683+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:24:08.684+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:24:08.734+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:24:08.735+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:24:08.857+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:24:08.885+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:24:08.885+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:24:08.914+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:24:08.913+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:24:08.927+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.389 seconds
[2024-08-09T00:24:39.495+0000] {processor.py:161} INFO - Started process (PID=485) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:24:39.497+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:24:39.502+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:24:39.501+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:24:39.629+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:24:39.630+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:24:39.672+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:24:39.672+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:24:39.794+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:24:39.824+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:24:39.823+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:24:39.837+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:24:39.837+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:24:39.846+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.362 seconds
[2024-08-09T00:25:10.759+0000] {processor.py:161} INFO - Started process (PID=487) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:25:10.762+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:25:10.767+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:25:10.766+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:25:10.893+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:25:10.894+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:25:10.929+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:25:10.929+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:25:11.068+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:25:11.092+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:25:11.092+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:25:11.106+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:25:11.106+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:25:11.114+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.387 seconds
[2024-08-09T00:25:41.315+0000] {processor.py:161} INFO - Started process (PID=489) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:25:41.317+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:25:41.322+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:25:41.321+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:25:41.452+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:25:41.452+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:25:41.486+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:25:41.487+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:25:41.608+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:25:41.632+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:25:41.632+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:25:41.645+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:25:41.645+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:25:41.658+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.357 seconds
[2024-08-09T00:26:11.990+0000] {processor.py:161} INFO - Started process (PID=491) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:26:11.993+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:26:11.997+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:26:11.997+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:26:12.130+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:26:12.130+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:26:12.166+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:26:12.166+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:26:12.288+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:26:12.323+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:26:12.323+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:26:12.339+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:26:12.339+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:26:12.347+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.369 seconds
[2024-08-09T00:26:42.511+0000] {processor.py:161} INFO - Started process (PID=493) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:26:42.514+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:26:42.519+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:26:42.518+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:26:42.644+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:26:42.645+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:26:42.695+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:26:42.695+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:26:42.815+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:26:42.840+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:26:42.840+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:26:42.854+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:26:42.854+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:26:42.862+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.369 seconds
[2024-08-09T00:27:13.138+0000] {processor.py:161} INFO - Started process (PID=495) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:27:13.140+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:27:13.145+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:27:13.144+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:27:13.280+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:27:13.281+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:27:13.326+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:27:13.326+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:27:13.446+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:27:13.468+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:27:13.468+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:27:13.483+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:27:13.483+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:27:13.496+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.378 seconds
[2024-08-09T00:27:43.723+0000] {processor.py:161} INFO - Started process (PID=497) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:27:43.725+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:27:43.731+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:27:43.730+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:27:43.873+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:27:43.873+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:27:43.922+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:27:43.923+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:27:44.056+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:27:44.083+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:27:44.083+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:27:44.097+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:27:44.096+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:27:44.113+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.406 seconds
[2024-08-09T00:28:14.372+0000] {processor.py:161} INFO - Started process (PID=499) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:28:14.375+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:28:14.397+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:28:14.396+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:28:14.519+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:28:14.519+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:28:14.574+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:28:14.575+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:28:14.696+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:28:14.719+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:28:14.719+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:28:14.733+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:28:14.733+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:28:14.741+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.393 seconds
[2024-08-09T00:28:44.911+0000] {processor.py:161} INFO - Started process (PID=501) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:28:44.914+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:28:44.918+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:28:44.917+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:28:45.104+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:28:45.104+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:28:45.142+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:28:45.142+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:28:45.262+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:28:45.297+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:28:45.297+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:28:45.311+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:28:45.311+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:28:45.320+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.423 seconds
[2024-08-09T00:29:15.680+0000] {processor.py:161} INFO - Started process (PID=503) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:29:15.682+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:29:15.687+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:29:15.687+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:29:15.813+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:29:15.813+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:29:15.867+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:29:15.867+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:29:16.015+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:29:16.036+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:29:16.036+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:29:16.050+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:29:16.050+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:29:16.059+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.392 seconds
[2024-08-09T00:29:46.534+0000] {processor.py:161} INFO - Started process (PID=505) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:29:46.536+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:29:46.540+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:29:46.540+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:29:46.672+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:29:46.672+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:29:46.708+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:29:46.708+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:29:46.835+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:29:46.857+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:29:46.857+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:29:46.871+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:29:46.870+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:29:46.879+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.385 seconds
[2024-08-09T00:30:17.064+0000] {processor.py:161} INFO - Started process (PID=507) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:30:17.066+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:30:17.071+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:30:17.070+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:30:17.205+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:30:17.205+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:30:17.242+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:30:17.243+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:30:17.370+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:30:17.393+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:30:17.393+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:30:17.407+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:30:17.407+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:30:17.416+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.367 seconds
[2024-08-09T00:30:47.683+0000] {processor.py:161} INFO - Started process (PID=509) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:30:47.684+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:30:47.689+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:30:47.688+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:30:47.821+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:30:47.821+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:30:47.869+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:30:47.869+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:30:48.001+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:30:48.023+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:30:48.023+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:30:48.037+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:30:48.037+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:30:48.046+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.397 seconds
[2024-08-09T00:31:18.774+0000] {processor.py:161} INFO - Started process (PID=511) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:31:18.780+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:31:18.793+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:31:18.791+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:31:18.933+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:31:18.934+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:31:18.972+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:31:18.973+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:31:19.096+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:31:19.119+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:31:19.118+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:31:19.132+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:31:19.132+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:31:19.141+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.381 seconds
[2024-08-09T00:31:49.497+0000] {processor.py:161} INFO - Started process (PID=513) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:31:49.501+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:31:49.505+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:31:49.505+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:31:49.632+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:31:49.633+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:31:49.681+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:31:49.681+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:31:49.803+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:31:49.827+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:31:49.827+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:31:49.841+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:31:49.841+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:31:49.861+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.375 seconds
[2024-08-09T00:32:20.005+0000] {processor.py:161} INFO - Started process (PID=515) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:32:20.006+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:32:20.011+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:32:20.010+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:32:20.149+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:32:20.150+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:32:20.198+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:32:20.198+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:32:20.318+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:32:20.341+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:32:20.341+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:32:20.355+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:32:20.355+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:32:20.363+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.373 seconds
[2024-08-09T00:32:50.690+0000] {processor.py:161} INFO - Started process (PID=517) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:32:50.692+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:32:50.700+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:32:50.696+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:32:50.822+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:32:50.822+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:32:50.858+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:32:50.858+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:32:50.997+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:32:51.019+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:32:51.018+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:32:51.032+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:32:51.032+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:32:51.040+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.363 seconds
[2024-08-09T00:33:21.440+0000] {processor.py:161} INFO - Started process (PID=519) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:33:21.441+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:33:21.446+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:33:21.445+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:33:21.578+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:33:21.578+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:33:21.613+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:33:21.613+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:33:21.734+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:33:21.758+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:33:21.758+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:33:21.771+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:33:21.771+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:33:21.780+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.364 seconds
[2024-08-09T00:33:52.187+0000] {processor.py:161} INFO - Started process (PID=521) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:33:52.189+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:33:52.195+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:33:52.194+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:33:52.347+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:33:52.348+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:33:52.383+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:33:52.383+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:33:52.515+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:33:52.538+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:33:52.538+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:33:52.552+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:33:52.552+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:33:52.575+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.408 seconds
[2024-08-09T00:34:22.844+0000] {processor.py:161} INFO - Started process (PID=523) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:34:22.847+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:34:22.855+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:34:22.853+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:34:23.015+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:34:23.015+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:34:23.051+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:34:23.051+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:34:23.187+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:34:23.219+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:34:23.219+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:34:23.233+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:34:23.233+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:34:23.241+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.413 seconds
[2024-08-09T00:34:53.602+0000] {processor.py:161} INFO - Started process (PID=525) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:34:53.604+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:34:53.609+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:34:53.608+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:34:53.764+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:34:53.765+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:34:53.801+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:34:53.801+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:34:53.982+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:34:54.028+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:34:54.028+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:34:54.043+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:34:54.043+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:34:54.063+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.486 seconds
[2024-08-09T00:35:24.501+0000] {processor.py:161} INFO - Started process (PID=527) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:35:24.504+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:35:24.509+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:35:24.508+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:35:24.645+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:35:24.645+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:35:24.680+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:35:24.680+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:35:24.822+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:35:24.849+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:35:24.848+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:35:24.873+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:35:24.872+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:35:24.881+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.395 seconds
[2024-08-09T00:35:55.534+0000] {processor.py:161} INFO - Started process (PID=529) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:35:55.536+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:35:55.542+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:35:55.541+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:35:55.676+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:35:55.677+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:35:55.724+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:35:55.724+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:35:55.848+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:35:55.874+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:35:55.874+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:35:55.896+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:35:55.896+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:35:55.906+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.387 seconds
[2024-08-09T00:36:26.329+0000] {processor.py:161} INFO - Started process (PID=531) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:36:26.331+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:36:26.336+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:36:26.336+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:36:26.468+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:36:26.468+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:36:26.503+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:36:26.504+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:36:26.630+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:36:26.653+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:36:26.653+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:36:26.669+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:36:26.669+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:36:26.688+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.387 seconds
[2024-08-09T00:36:56.882+0000] {processor.py:161} INFO - Started process (PID=533) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:36:56.885+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:36:56.890+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:36:56.889+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:36:57.019+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:36:57.019+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:36:57.076+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:36:57.076+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:36:57.207+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:36:57.232+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:36:57.232+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:36:57.268+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:36:57.268+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:36:57.277+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.423 seconds
[2024-08-09T00:37:27.399+0000] {processor.py:161} INFO - Started process (PID=535) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:37:27.401+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:37:27.405+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:37:27.405+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:37:27.565+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:37:27.566+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:37:27.602+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:37:27.602+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:37:27.741+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:37:27.769+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:37:27.768+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:37:27.781+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:37:27.781+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:37:27.791+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.404 seconds
[2024-08-09T00:37:58.023+0000] {processor.py:161} INFO - Started process (PID=537) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:37:58.031+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:37:58.045+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:37:58.045+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:37:58.171+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:37:58.171+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:37:58.205+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:37:58.205+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:37:58.339+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:37:58.365+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:37:58.365+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:37:58.382+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:37:58.382+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:37:58.389+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.382 seconds
[2024-08-09T00:38:28.523+0000] {processor.py:161} INFO - Started process (PID=539) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:38:28.529+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:38:28.534+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:38:28.533+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:38:28.719+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:38:28.720+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:38:28.749+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:38:28.750+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:38:28.931+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:38:28.978+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:38:28.978+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:38:29.001+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:38:29.001+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:38:29.016+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.519 seconds
[2024-08-09T00:38:59.186+0000] {processor.py:161} INFO - Started process (PID=541) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:38:59.190+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:38:59.195+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:38:59.194+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:38:59.327+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:38:59.327+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:38:59.356+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:38:59.357+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:38:59.475+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:38:59.503+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:38:59.503+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:38:59.531+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:38:59.531+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:38:59.544+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.396 seconds
[2024-08-09T00:39:29.915+0000] {processor.py:161} INFO - Started process (PID=543) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:39:29.918+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:39:29.938+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:39:29.936+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:39:30.123+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:39:30.123+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:39:30.154+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:39:30.154+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:39:30.271+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:39:30.307+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:39:30.306+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:39:30.332+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:39:30.331+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:39:30.356+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.454 seconds
[2024-08-09T00:40:00.526+0000] {processor.py:161} INFO - Started process (PID=545) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:40:00.528+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:40:00.533+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:40:00.533+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:40:00.662+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:40:00.662+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:40:00.692+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:40:00.692+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:40:00.804+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:40:00.829+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:40:00.829+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:40:00.854+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:40:00.854+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:40:00.864+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.352 seconds
[2024-08-09T00:40:31.164+0000] {processor.py:161} INFO - Started process (PID=547) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:40:31.167+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:40:31.176+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:40:31.175+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:40:31.301+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:40:31.302+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:40:31.333+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:40:31.333+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:40:31.449+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:40:31.474+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:40:31.474+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:40:31.487+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:40:31.486+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:40:31.494+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.346 seconds
[2024-08-09T00:41:01.715+0000] {processor.py:161} INFO - Started process (PID=549) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:41:01.719+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:41:01.725+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:41:01.724+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:41:01.862+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:41:01.863+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:41:01.893+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:41:01.893+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:41:02.017+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:41:02.053+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:41:02.053+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:41:02.066+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:41:02.066+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:41:02.075+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.386 seconds
[2024-08-09T00:41:32.352+0000] {processor.py:161} INFO - Started process (PID=551) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:41:32.354+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:41:32.359+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:41:32.358+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:41:32.512+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:41:32.512+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:41:32.540+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:41:32.541+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:41:32.654+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:41:32.678+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:41:32.678+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:41:32.690+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:41:32.690+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:41:32.699+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.360 seconds
[2024-08-09T00:42:02.871+0000] {processor.py:161} INFO - Started process (PID=553) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:42:02.873+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:42:02.877+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:42:02.877+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:42:03.004+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:42:03.004+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:42:03.042+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:42:03.042+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:42:03.158+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:42:03.183+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:42:03.183+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:42:03.196+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:42:03.196+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:42:03.212+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.370 seconds
[2024-08-09T00:42:33.486+0000] {processor.py:161} INFO - Started process (PID=555) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:42:33.489+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:42:33.494+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:42:33.493+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:42:33.636+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:42:33.636+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:42:33.676+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:42:33.677+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:42:33.789+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:42:33.820+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:42:33.820+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:42:33.833+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:42:33.833+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:42:33.842+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.371 seconds
[2024-08-09T00:43:04.060+0000] {processor.py:161} INFO - Started process (PID=557) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:43:04.062+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:43:04.067+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:43:04.067+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:43:04.199+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:43:04.199+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:43:04.230+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:43:04.230+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:43:04.349+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:43:04.387+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:43:04.386+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:43:04.399+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:43:04.399+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:43:04.407+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.363 seconds
[2024-08-09T00:43:34.718+0000] {processor.py:161} INFO - Started process (PID=559) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:43:34.720+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:43:34.724+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:43:34.724+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:43:34.848+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:43:34.848+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:43:34.878+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:43:34.878+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:43:35.160+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:43:35.201+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:43:35.200+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:43:35.213+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:43:35.213+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:43:35.222+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.515 seconds
[2024-08-09T00:44:05.630+0000] {processor.py:161} INFO - Started process (PID=561) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:44:05.632+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:44:05.637+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:44:05.636+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:44:05.754+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:44:05.754+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:44:05.789+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:44:05.789+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:44:05.895+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:44:05.937+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:44:05.937+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:44:05.957+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:44:05.956+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:44:05.965+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.345 seconds
[2024-08-09T00:44:36.324+0000] {processor.py:161} INFO - Started process (PID=563) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:44:36.326+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:44:36.330+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:44:36.330+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:44:36.454+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:44:36.455+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:44:36.483+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:44:36.483+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:44:36.601+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:44:36.627+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:44:36.627+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:44:36.641+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:44:36.641+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:44:36.656+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.348 seconds
[2024-08-09T00:45:07.327+0000] {processor.py:161} INFO - Started process (PID=565) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:45:07.329+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:45:07.334+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:45:07.333+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:45:07.461+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:45:07.462+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:45:07.492+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:45:07.493+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:45:07.609+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:45:07.635+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:45:07.635+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:45:07.660+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:45:07.660+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:45:07.668+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.355 seconds
[2024-08-09T00:45:38.194+0000] {processor.py:161} INFO - Started process (PID=567) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:45:38.196+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:45:38.200+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:45:38.200+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:45:38.317+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:45:38.318+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:45:38.359+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:45:38.359+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:45:38.466+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:45:38.500+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:45:38.500+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:45:38.514+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:45:38.513+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:45:38.522+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.339 seconds
[2024-08-09T00:46:08.710+0000] {processor.py:161} INFO - Started process (PID=569) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:46:08.713+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:46:08.717+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:46:08.716+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:46:08.843+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:46:08.843+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:46:08.872+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:46:08.872+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:46:09.005+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:46:09.031+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:46:09.030+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:46:09.057+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:46:09.057+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:46:09.066+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.370 seconds
[2024-08-09T00:46:39.312+0000] {processor.py:161} INFO - Started process (PID=571) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:46:39.314+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:46:39.319+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:46:39.318+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:46:39.452+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:46:39.452+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:46:39.483+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:46:39.483+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:46:39.605+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:46:39.629+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:46:39.629+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:46:39.642+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:46:39.642+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:46:39.650+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.353 seconds
[2024-08-09T00:47:09.884+0000] {processor.py:161} INFO - Started process (PID=573) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:47:09.886+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:47:09.900+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:47:09.897+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:47:10.025+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:47:10.025+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:47:10.070+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:47:10.070+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:47:10.180+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:47:10.229+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:47:10.229+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:47:10.244+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:47:10.244+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:47:10.261+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.392 seconds
[2024-08-09T00:47:40.459+0000] {processor.py:161} INFO - Started process (PID=575) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:47:40.461+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:47:40.465+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:47:40.465+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:47:40.584+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:47:40.585+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:47:40.615+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:47:40.615+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:47:40.738+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:47:40.762+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:47:40.761+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:47:40.774+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:47:40.774+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:47:40.786+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.364 seconds
[2024-08-09T00:48:11.096+0000] {processor.py:161} INFO - Started process (PID=577) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:48:11.101+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:48:11.118+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:48:11.113+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:48:11.243+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:48:11.243+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:48:11.274+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:48:11.274+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:48:11.393+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:48:11.419+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:48:11.419+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:48:11.432+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:48:11.431+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:48:11.440+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.367 seconds
[2024-08-09T00:48:41.639+0000] {processor.py:161} INFO - Started process (PID=579) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:48:41.641+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:48:41.646+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:48:41.645+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:48:41.764+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:48:41.764+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:48:41.801+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:48:41.801+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:48:41.916+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:48:41.979+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:48:41.979+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:48:42.058+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:48:42.058+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:48:42.074+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.469 seconds
[2024-08-09T00:49:12.231+0000] {processor.py:161} INFO - Started process (PID=581) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:49:12.234+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:49:12.240+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:49:12.239+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:49:12.356+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:49:12.356+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:49:12.399+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:49:12.399+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:49:12.515+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:49:12.540+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:49:12.540+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:49:12.554+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:49:12.554+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:49:12.569+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.352 seconds
[2024-08-09T00:49:43.033+0000] {processor.py:161} INFO - Started process (PID=583) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:49:43.035+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:49:43.040+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:49:43.039+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:49:43.158+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:49:43.158+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:49:43.187+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:49:43.187+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:49:43.309+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:49:43.340+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:49:43.340+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:49:43.353+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:49:43.353+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:49:43.362+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.360 seconds
[2024-08-09T00:50:13.676+0000] {processor.py:161} INFO - Started process (PID=585) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:50:13.679+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:50:13.683+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:50:13.683+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:50:13.806+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:50:13.806+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:50:13.836+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:50:13.836+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:50:14.174+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:50:14.224+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:50:14.223+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:50:14.239+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:50:14.239+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:50:14.249+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.587 seconds
[2024-08-09T00:50:44.751+0000] {processor.py:161} INFO - Started process (PID=587) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:50:44.753+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:50:44.757+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:50:44.757+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:50:44.886+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:50:44.886+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:50:44.915+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:50:44.915+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:50:45.039+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:50:45.072+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:50:45.071+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:50:45.088+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:50:45.087+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:50:45.095+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.359 seconds
[2024-08-09T00:51:15.830+0000] {processor.py:161} INFO - Started process (PID=589) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:51:15.839+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:51:15.845+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:51:15.844+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:51:15.968+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:51:15.969+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:51:15.998+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:51:15.998+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:51:16.111+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:51:16.134+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:51:16.134+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:51:16.151+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:51:16.150+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:51:16.159+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.351 seconds
[2024-08-09T00:51:46.342+0000] {processor.py:161} INFO - Started process (PID=591) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:51:46.344+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:51:46.349+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:51:46.348+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:51:46.472+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:51:46.473+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:51:46.509+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:51:46.509+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:51:46.622+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:51:46.644+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:51:46.644+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:51:46.672+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:51:46.672+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:51:46.680+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.355 seconds
[2024-08-09T00:52:17.016+0000] {processor.py:161} INFO - Started process (PID=593) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:52:17.018+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:52:17.022+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:52:17.022+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:52:17.136+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:52:17.137+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:52:17.166+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:52:17.166+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:52:17.281+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:52:17.302+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:52:17.302+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:52:17.315+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:52:17.315+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:52:17.323+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.337 seconds
[2024-08-09T00:52:47.741+0000] {processor.py:161} INFO - Started process (PID=595) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:52:47.743+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:52:47.747+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:52:47.747+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:52:47.866+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:52:47.866+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:52:47.902+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:52:47.903+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:52:48.010+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:52:48.044+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:52:48.044+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:52:48.057+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:52:48.056+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:52:48.065+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.362 seconds
[2024-08-09T00:53:19.030+0000] {processor.py:161} INFO - Started process (PID=597) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:53:19.032+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:53:19.039+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:53:19.038+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:53:19.177+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:53:19.177+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:53:19.206+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:53:19.206+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:53:19.321+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:53:19.343+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:53:19.343+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:53:19.356+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:53:19.356+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:53:19.365+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.352 seconds
[2024-08-09T00:53:49.557+0000] {processor.py:161} INFO - Started process (PID=599) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:53:49.559+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:53:49.564+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:53:49.563+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:53:49.689+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:53:49.690+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:53:49.720+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:53:49.720+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:53:49.836+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:53:49.858+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:53:49.858+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:53:49.871+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:53:49.871+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:53:49.889+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.366 seconds
[2024-08-09T00:54:20.132+0000] {processor.py:161} INFO - Started process (PID=601) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:54:20.134+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:54:20.139+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:54:20.138+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:54:20.248+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:54:20.249+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:54:20.287+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:54:20.287+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:54:20.396+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:54:20.433+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:54:20.433+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:54:20.446+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:54:20.446+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:54:20.454+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.362 seconds
[2024-08-09T00:54:50.615+0000] {processor.py:161} INFO - Started process (PID=603) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:54:50.624+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:54:50.629+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:54:50.628+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:54:50.743+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:54:50.743+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:54:50.775+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:54:50.775+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:54:50.895+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:54:50.919+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:54:50.919+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:54:50.946+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:54:50.946+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:54:50.961+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.380 seconds
[2024-08-09T00:55:21.271+0000] {processor.py:161} INFO - Started process (PID=605) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:55:21.274+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:55:21.279+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:55:21.278+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:55:21.409+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:55:21.410+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:55:21.438+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:55:21.439+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:55:21.553+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:55:21.576+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:55:21.576+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:55:21.589+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:55:21.589+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:55:21.609+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.350 seconds
[2024-08-09T00:55:51.857+0000] {processor.py:161} INFO - Started process (PID=607) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:55:51.860+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:55:51.865+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:55:51.864+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:55:52.011+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:55:52.011+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:55:52.042+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:55:52.042+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:55:52.158+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:55:52.185+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:55:52.185+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:55:52.210+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:55:52.210+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:55:52.219+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.376 seconds
[2024-08-09T00:56:22.485+0000] {processor.py:161} INFO - Started process (PID=609) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:56:22.488+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:56:22.505+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:56:22.503+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:56:22.624+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:56:22.624+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:56:22.664+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:56:22.664+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:56:22.788+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:56:22.811+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:56:22.810+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:56:22.823+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:56:22.823+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:56:22.831+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.372 seconds
[2024-08-09T00:56:53.394+0000] {processor.py:161} INFO - Started process (PID=611) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:56:53.396+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:56:53.401+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:56:53.400+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:56:53.539+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:56:53.540+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:56:53.568+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:56:53.569+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:56:53.691+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:56:53.724+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:56:53.724+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:56:53.737+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:56:53.737+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:56:53.746+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.364 seconds
[2024-08-09T00:57:24.178+0000] {processor.py:161} INFO - Started process (PID=613) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:57:24.180+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:57:24.185+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:57:24.184+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:57:24.306+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:57:24.307+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:57:24.336+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:57:24.336+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:57:24.458+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:57:24.483+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:57:24.483+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:57:24.496+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:57:24.496+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:57:24.504+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.340 seconds
[2024-08-09T00:57:54.671+0000] {processor.py:161} INFO - Started process (PID=615) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:57:54.674+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:57:54.678+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:57:54.677+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:57:54.804+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:57:54.804+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:57:54.843+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:57:54.843+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:57:54.974+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:57:54.998+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:57:54.998+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:57:55.012+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:57:55.011+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:57:55.022+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.381 seconds
[2024-08-09T00:58:25.315+0000] {processor.py:161} INFO - Started process (PID=617) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:58:25.319+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:58:25.326+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:58:25.325+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:58:25.450+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:58:25.451+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:58:25.491+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:58:25.492+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:58:25.598+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:58:25.628+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:58:25.628+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:58:25.641+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:58:25.641+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:58:25.650+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.358 seconds
[2024-08-09T00:58:55.898+0000] {processor.py:161} INFO - Started process (PID=619) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:58:55.900+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:58:55.906+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:58:55.905+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:58:56.051+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:58:56.051+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:58:56.081+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:58:56.081+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:58:56.207+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:58:56.230+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:58:56.230+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:58:56.243+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:58:56.243+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:58:56.251+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.368 seconds
[2024-08-09T00:59:26.389+0000] {processor.py:161} INFO - Started process (PID=621) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:59:26.392+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:59:26.397+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:59:26.396+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:59:26.511+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:59:26.511+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:59:26.552+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:59:26.552+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:59:26.689+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:59:26.713+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:59:26.713+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:59:26.735+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:59:26.735+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:59:26.745+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.379 seconds
[2024-08-09T00:59:57.105+0000] {processor.py:161} INFO - Started process (PID=623) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:59:57.107+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T00:59:57.112+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:59:57.111+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:59:57.239+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:59:57.240+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:59:57.269+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T00:59:57.269+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T00:59:57.385+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T00:59:57.408+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:59:57.408+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T00:59:57.421+0000] {logging_mixin.py:188} INFO - [2024-08-09T00:59:57.421+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T00:59:57.429+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.345 seconds
[2024-08-09T01:00:27.877+0000] {processor.py:161} INFO - Started process (PID=625) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:00:27.879+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:00:27.884+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:00:27.884+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:00:28.043+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:00:28.043+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:00:28.086+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:00:28.086+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:00:28.205+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:00:28.235+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:00:28.234+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:00:28.252+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:00:28.252+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:00:28.261+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.427 seconds
[2024-08-09T01:00:58.488+0000] {processor.py:161} INFO - Started process (PID=627) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:00:58.492+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:00:58.496+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:00:58.496+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:00:58.625+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:00:58.626+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:00:58.661+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:00:58.661+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:00:58.772+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:00:58.800+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:00:58.800+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:00:58.825+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:00:58.825+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:00:58.834+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.367 seconds
[2024-08-09T01:01:29.099+0000] {processor.py:161} INFO - Started process (PID=629) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:01:29.101+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:01:29.106+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:01:29.105+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:01:29.229+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:01:29.229+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:01:29.259+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:01:29.259+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:01:29.371+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:01:29.395+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:01:29.395+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:01:29.409+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:01:29.408+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:01:29.417+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.349 seconds
[2024-08-09T01:01:59.747+0000] {processor.py:161} INFO - Started process (PID=631) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:01:59.749+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:01:59.754+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:01:59.753+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:01:59.871+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:01:59.871+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:01:59.907+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:01:59.907+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:02:00.080+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:02:00.118+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:02:00.118+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:02:00.131+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:02:00.131+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:02:00.140+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.426 seconds
[2024-08-09T01:02:30.548+0000] {processor.py:161} INFO - Started process (PID=633) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:02:30.550+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:02:30.555+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:02:30.554+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:02:30.680+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:02:30.680+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:02:30.707+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:02:30.708+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:02:30.819+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:02:30.842+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:02:30.842+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:02:30.855+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:02:30.855+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:02:30.863+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.331 seconds
[2024-08-09T01:03:01.122+0000] {processor.py:161} INFO - Started process (PID=635) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:03:01.125+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:03:01.129+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:03:01.128+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:03:01.262+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:03:01.262+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:03:01.303+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:03:01.303+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:03:01.419+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:03:01.445+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:03:01.444+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:03:01.457+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:03:01.457+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:03:01.465+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.375 seconds
[2024-08-09T01:03:31.935+0000] {processor.py:161} INFO - Started process (PID=637) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:03:31.937+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:03:31.942+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:03:31.941+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:03:32.066+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:03:32.067+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:03:32.097+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:03:32.097+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:03:32.221+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:03:32.246+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:03:32.245+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:03:32.258+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:03:32.258+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:03:32.266+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.359 seconds
[2024-08-09T01:04:02.651+0000] {processor.py:161} INFO - Started process (PID=639) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:04:02.653+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:04:02.657+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:04:02.656+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:04:02.779+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:04:02.780+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:04:02.808+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:04:02.809+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:04:02.930+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:04:02.957+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:04:02.956+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:04:02.970+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:04:02.970+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:04:02.979+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.343 seconds
[2024-08-09T01:04:33.116+0000] {processor.py:161} INFO - Started process (PID=641) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:04:33.119+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:04:33.123+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:04:33.123+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:04:33.257+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:04:33.257+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:04:33.288+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:04:33.288+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:04:33.420+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:04:33.447+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:04:33.447+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:04:33.470+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:04:33.470+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:04:33.479+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.379 seconds
[2024-08-09T01:05:03.787+0000] {processor.py:161} INFO - Started process (PID=643) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:05:03.790+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:05:03.794+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:05:03.793+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:05:03.934+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:05:03.935+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:05:03.973+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:05:03.973+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:05:04.081+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:05:04.120+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:05:04.119+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:05:04.133+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:05:04.133+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:05:04.141+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.369 seconds
[2024-08-09T01:05:34.296+0000] {processor.py:161} INFO - Started process (PID=645) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:05:34.298+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:05:34.302+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:05:34.302+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:05:34.430+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:05:34.430+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:05:34.465+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:05:34.465+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:05:34.574+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:05:34.609+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:05:34.609+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:05:34.623+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:05:34.622+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:05:34.631+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.349 seconds
[2024-08-09T01:06:04.956+0000] {processor.py:161} INFO - Started process (PID=647) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:06:04.959+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:06:04.963+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:06:04.962+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:06:05.088+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:06:05.089+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:06:05.118+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:06:05.118+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:06:05.234+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:06:05.258+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:06:05.258+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:06:05.272+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:06:05.272+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:06:05.280+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.335 seconds
[2024-08-09T01:06:35.431+0000] {processor.py:161} INFO - Started process (PID=649) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:06:35.434+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:06:35.438+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:06:35.437+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:06:35.566+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:06:35.566+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:06:35.610+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:06:35.610+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:06:35.731+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:06:35.757+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:06:35.757+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:06:35.771+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:06:35.770+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:06:35.779+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.374 seconds
[2024-08-09T01:07:06.095+0000] {processor.py:161} INFO - Started process (PID=651) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:07:06.098+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:07:06.102+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:07:06.101+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:07:06.217+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:07:06.218+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:07:06.247+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:07:06.247+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:07:06.361+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:07:06.385+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:07:06.385+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:07:06.409+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:07:06.409+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:07:06.422+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.354 seconds
[2024-08-09T01:07:36.597+0000] {processor.py:161} INFO - Started process (PID=653) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:07:36.599+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:07:36.604+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:07:36.603+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:07:36.725+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:07:36.725+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:07:36.761+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:07:36.761+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:07:36.867+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:07:36.905+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:07:36.905+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:07:36.934+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:07:36.933+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:07:36.943+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.361 seconds
[2024-08-09T01:08:07.128+0000] {processor.py:161} INFO - Started process (PID=655) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:08:07.130+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:08:07.135+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:08:07.134+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:08:07.264+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:08:07.264+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:08:07.295+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:08:07.295+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:08:07.405+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:08:07.430+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:08:07.429+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:08:07.444+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:08:07.444+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:08:07.464+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.350 seconds
[2024-08-09T01:08:37.969+0000] {processor.py:161} INFO - Started process (PID=657) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:08:37.970+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:08:37.974+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:08:37.974+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:08:38.086+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:08:38.086+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:08:38.121+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:08:38.121+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:08:38.230+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:08:38.266+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:08:38.266+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:08:38.280+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:08:38.280+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:08:38.289+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.332 seconds
[2024-08-09T01:09:08.622+0000] {processor.py:161} INFO - Started process (PID=659) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:09:08.635+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:09:08.642+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:09:08.641+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:09:08.757+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:09:08.758+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:09:08.786+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:09:08.786+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:09:08.908+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:09:08.950+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:09:08.950+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:09:08.965+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:09:08.965+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:09:08.974+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.369 seconds
[2024-08-09T01:09:39.445+0000] {processor.py:161} INFO - Started process (PID=661) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:09:39.448+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:09:39.453+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:09:39.453+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:09:39.580+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:09:39.580+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:09:39.610+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:09:39.610+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:09:39.728+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:09:39.753+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:09:39.753+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:09:39.765+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:09:39.765+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:09:39.774+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.362 seconds
[2024-08-09T01:10:09.924+0000] {processor.py:161} INFO - Started process (PID=663) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:10:09.927+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:10:09.932+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:10:09.931+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:10:10.047+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:10:10.047+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:10:10.082+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:10:10.083+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:10:10.200+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:10:10.225+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:10:10.224+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:10:10.239+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:10:10.239+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:10:10.247+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.367 seconds
[2024-08-09T01:10:40.586+0000] {processor.py:161} INFO - Started process (PID=665) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:10:40.588+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:10:40.592+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:10:40.591+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:10:40.702+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:10:40.703+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:10:40.737+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:10:40.738+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:10:40.859+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:10:40.901+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:10:40.901+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:10:41.006+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:10:41.002+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:10:41.031+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.456 seconds
[2024-08-09T01:11:11.615+0000] {processor.py:161} INFO - Started process (PID=667) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:11:11.618+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:11:11.622+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:11:11.621+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:11:11.731+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:11:11.731+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:11:11.770+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:11:11.770+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:11:11.875+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:11:11.917+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:11:11.917+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:11:11.945+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:11:11.945+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:11:11.955+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.355 seconds
[2024-08-09T01:11:42.538+0000] {processor.py:161} INFO - Started process (PID=669) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:11:42.540+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:11:42.545+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:11:42.544+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:11:42.651+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:11:42.651+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:11:42.687+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:11:42.687+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:11:42.793+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:11:42.831+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:11:42.831+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:11:42.847+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:11:42.847+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:11:42.855+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.330 seconds
[2024-08-09T01:12:12.971+0000] {processor.py:161} INFO - Started process (PID=671) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:12:12.974+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:12:12.979+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:12:12.978+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:12:13.104+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:12:13.105+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:12:13.143+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:12:13.143+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:12:13.250+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:12:13.284+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:12:13.284+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:12:13.302+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:12:13.302+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:12:13.310+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.353 seconds
[2024-08-09T01:12:43.699+0000] {processor.py:161} INFO - Started process (PID=673) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:12:43.701+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:12:43.705+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:12:43.705+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:12:43.816+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:12:43.817+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:12:43.851+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:12:43.852+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:12:43.974+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:12:43.998+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:12:43.998+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:12:44.010+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:12:44.010+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:12:44.019+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.347 seconds
[2024-08-09T01:13:14.749+0000] {processor.py:161} INFO - Started process (PID=675) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:13:14.751+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:13:14.756+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:13:14.755+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:13:14.896+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:13:14.896+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:13:14.955+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:13:14.955+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:13:15.072+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:13:15.093+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:13:15.093+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:13:15.106+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:13:15.106+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:13:15.120+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.388 seconds
[2024-08-09T01:13:45.493+0000] {processor.py:161} INFO - Started process (PID=677) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:13:45.496+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:13:45.501+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:13:45.500+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:13:45.617+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:13:45.617+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:13:45.654+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:13:45.655+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:13:45.784+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:13:45.815+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:13:45.815+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:13:45.834+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:13:45.834+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:13:45.842+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.363 seconds
[2024-08-09T01:14:16.298+0000] {processor.py:161} INFO - Started process (PID=679) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:14:16.311+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:14:16.331+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:14:16.330+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:14:16.450+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:14:16.451+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:14:16.489+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:14:16.489+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:14:16.596+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:14:16.626+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:14:16.626+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:14:16.646+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:14:16.646+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:14:16.654+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.370 seconds
[2024-08-09T01:14:46.796+0000] {processor.py:161} INFO - Started process (PID=681) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:14:46.797+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:14:46.802+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:14:46.801+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:14:46.922+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:14:46.923+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:14:46.959+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:14:46.959+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:14:47.072+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:14:47.094+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:14:47.094+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:14:47.120+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:14:47.120+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:14:47.129+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.364 seconds
[2024-08-09T01:15:17.792+0000] {processor.py:161} INFO - Started process (PID=683) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:15:17.793+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:15:17.798+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:15:17.797+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:15:17.915+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:15:17.915+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:15:17.943+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:15:17.943+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:15:18.060+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:15:18.082+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:15:18.082+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:15:18.095+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:15:18.095+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:15:18.103+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.325 seconds
[2024-08-09T01:15:48.290+0000] {processor.py:161} INFO - Started process (PID=685) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:15:48.295+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:15:48.300+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:15:48.300+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:15:48.453+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:15:48.453+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:15:48.485+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:15:48.485+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:15:48.601+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:15:48.631+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:15:48.630+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:15:48.648+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:15:48.647+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:15:48.667+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.395 seconds
[2024-08-09T01:16:18.949+0000] {processor.py:161} INFO - Started process (PID=687) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:16:18.950+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:16:18.954+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:16:18.953+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:16:19.073+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:16:19.073+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:16:19.115+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:16:19.115+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:16:19.223+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:16:19.261+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:16:19.261+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:16:19.274+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:16:19.274+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:16:19.283+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.345 seconds
[2024-08-09T01:16:49.751+0000] {processor.py:161} INFO - Started process (PID=689) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:16:49.753+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:16:49.758+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:16:49.757+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:16:49.906+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:16:49.906+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:16:49.941+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:16:49.941+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:16:50.064+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:16:50.101+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:16:50.101+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:16:50.116+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:16:50.115+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:16:50.125+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.415 seconds
[2024-08-09T01:17:20.761+0000] {processor.py:161} INFO - Started process (PID=691) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:17:20.763+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:17:20.768+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:17:20.767+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:17:20.898+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:17:20.898+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:17:21.130+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:17:21.130+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:17:21.249+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:17:21.278+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:17:21.278+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:17:21.291+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:17:21.291+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:17:21.300+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.554 seconds
[2024-08-09T01:17:51.607+0000] {processor.py:161} INFO - Started process (PID=693) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:17:51.610+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:17:51.614+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:17:51.614+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:17:51.751+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:17:51.752+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:17:51.787+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:17:51.788+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:17:51.928+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:17:51.966+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:17:51.966+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:17:51.980+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:17:51.980+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:17:51.989+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.413 seconds
[2024-08-09T01:18:22.119+0000] {processor.py:161} INFO - Started process (PID=695) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:18:22.121+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:18:22.126+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:18:22.125+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:18:22.261+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:18:22.261+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:18:22.296+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:18:22.296+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:18:22.413+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:18:22.447+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:18:22.447+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:18:22.462+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:18:22.462+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:18:22.470+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.365 seconds
[2024-08-09T01:18:53.292+0000] {processor.py:161} INFO - Started process (PID=697) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:18:53.295+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:18:53.309+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:18:53.308+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:18:53.445+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:18:53.445+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:18:53.481+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:18:53.481+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:18:53.606+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:18:53.656+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:18:53.655+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:18:53.673+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:18:53.673+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:18:53.682+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.674 seconds
[2024-08-09T01:19:24.197+0000] {processor.py:161} INFO - Started process (PID=699) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:19:24.198+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:19:24.203+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:19:24.202+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:19:24.329+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:19:24.329+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:19:24.376+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:19:24.376+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:19:24.500+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:19:24.527+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:19:24.527+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:19:24.548+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:19:24.548+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:19:24.557+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.396 seconds
[2024-08-09T01:19:54.970+0000] {processor.py:161} INFO - Started process (PID=701) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:19:54.973+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:19:54.978+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:19:54.977+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:19:55.121+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:19:55.122+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:19:55.159+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:19:55.159+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:19:55.273+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:19:55.298+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:19:55.298+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:19:55.311+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:19:55.311+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:19:55.326+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.370 seconds
[2024-08-09T01:20:25.773+0000] {processor.py:161} INFO - Started process (PID=703) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:20:25.775+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:20:25.780+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:20:25.779+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:20:25.922+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:20:25.922+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:20:25.964+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:20:25.964+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:20:26.110+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:20:26.139+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:20:26.139+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:20:26.152+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:20:26.152+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:20:26.161+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.426 seconds
[2024-08-09T01:20:56.455+0000] {processor.py:161} INFO - Started process (PID=705) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:20:56.457+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:20:56.462+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:20:56.460+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:20:56.614+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:20:56.614+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:20:56.652+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:20:56.652+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:20:56.778+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:20:56.805+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:20:56.805+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:20:56.818+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:20:56.818+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:20:56.826+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.385 seconds
[2024-08-09T01:21:27.232+0000] {processor.py:161} INFO - Started process (PID=707) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:21:27.234+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:21:27.239+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:21:27.239+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:21:27.381+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:21:27.381+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:21:27.419+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:21:27.419+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:21:27.537+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:21:27.562+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:21:27.562+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:21:27.575+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:21:27.575+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:21:27.591+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.379 seconds
[2024-08-09T01:21:58.162+0000] {processor.py:161} INFO - Started process (PID=709) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:21:58.167+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:21:58.172+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:21:58.171+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:21:58.308+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:21:58.308+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:21:58.345+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:21:58.345+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:21:58.465+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:21:58.502+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:21:58.502+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:21:58.516+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:21:58.516+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:21:58.527+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.403 seconds
[2024-08-09T01:22:29.108+0000] {processor.py:161} INFO - Started process (PID=711) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:22:29.109+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:22:29.114+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:22:29.113+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:22:29.235+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:22:29.236+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:22:29.284+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:22:29.284+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:22:29.402+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:22:29.426+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:22:29.426+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:22:29.439+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:22:29.439+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:22:29.448+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.365 seconds
[2024-08-09T01:22:59.631+0000] {processor.py:161} INFO - Started process (PID=713) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:22:59.633+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:22:59.637+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:22:59.637+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:22:59.761+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:22:59.762+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:22:59.811+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:22:59.811+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:23:00.009+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:23:00.049+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:23:00.048+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:23:00.064+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:23:00.064+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:23:00.073+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.476 seconds
[2024-08-09T01:23:30.269+0000] {processor.py:161} INFO - Started process (PID=715) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:23:30.271+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:23:30.275+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:23:30.275+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:23:30.404+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:23:30.404+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:23:30.444+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:23:30.444+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:23:30.565+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:23:30.590+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:23:30.590+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:23:30.602+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:23:30.602+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:23:30.610+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.361 seconds
[2024-08-09T01:24:00.911+0000] {processor.py:161} INFO - Started process (PID=717) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:24:00.913+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:24:00.917+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:24:00.916+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:24:01.045+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:24:01.046+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:24:01.092+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:24:01.092+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:24:01.254+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:24:01.279+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:24:01.279+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:24:01.293+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:24:01.293+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:24:01.302+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.405 seconds
[2024-08-09T01:24:31.795+0000] {processor.py:161} INFO - Started process (PID=719) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:24:31.797+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:24:31.802+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:24:31.801+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:24:31.942+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:24:31.942+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:24:31.979+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:24:31.979+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:24:32.109+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:24:32.136+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:24:32.136+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:24:32.149+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:24:32.149+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:24:32.158+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.377 seconds
[2024-08-09T01:25:02.697+0000] {processor.py:161} INFO - Started process (PID=721) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:25:02.698+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:25:02.703+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:25:02.702+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:25:02.842+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:25:02.842+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:25:02.877+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:25:02.878+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:25:03.062+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:25:03.087+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:25:03.087+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:25:03.100+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:25:03.100+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:25:03.108+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.426 seconds
[2024-08-09T01:25:33.547+0000] {processor.py:161} INFO - Started process (PID=723) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:25:33.549+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:25:33.553+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:25:33.552+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:25:33.688+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:25:33.688+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:25:33.724+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:25:33.724+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:25:33.832+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:25:33.875+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:25:33.874+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:25:33.887+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:25:33.887+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:25:33.896+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.362 seconds
[2024-08-09T01:26:04.506+0000] {processor.py:161} INFO - Started process (PID=725) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:26:04.508+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:26:04.512+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:26:04.511+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:26:04.640+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:26:04.640+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:26:04.675+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:26:04.675+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:26:04.827+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:26:04.853+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:26:04.853+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:26:04.867+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:26:04.867+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:26:04.883+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.414 seconds
[2024-08-09T01:26:35.344+0000] {processor.py:161} INFO - Started process (PID=727) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:26:35.355+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:26:35.361+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:26:35.360+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:26:35.512+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:26:35.512+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:26:35.578+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:26:35.578+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:26:35.710+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:26:35.738+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:26:35.738+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:26:35.752+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:26:35.752+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:26:35.760+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.439 seconds
[2024-08-09T01:27:06.237+0000] {processor.py:161} INFO - Started process (PID=729) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:27:06.239+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:27:06.243+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:27:06.243+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:27:06.371+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:27:06.371+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:27:06.411+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:27:06.411+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:27:06.531+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:27:06.557+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:27:06.557+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:27:06.571+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:27:06.571+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:27:06.580+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.358 seconds
[2024-08-09T01:27:36.740+0000] {processor.py:161} INFO - Started process (PID=731) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:27:36.742+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:27:36.746+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:27:36.745+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:27:36.892+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:27:36.892+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:27:36.944+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:27:36.944+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:27:37.104+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:27:37.140+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:27:37.140+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:27:37.153+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:27:37.153+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:27:37.163+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.435 seconds
[2024-08-09T01:28:07.609+0000] {processor.py:161} INFO - Started process (PID=733) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:28:07.611+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:28:07.616+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:28:07.615+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:28:07.746+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:28:07.746+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:28:07.781+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:28:07.781+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:28:07.903+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:28:07.934+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:28:07.934+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:28:07.947+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:28:07.947+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:28:07.956+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.359 seconds
[2024-08-09T01:28:38.461+0000] {processor.py:161} INFO - Started process (PID=735) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:28:38.463+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:28:38.467+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:28:38.467+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:28:38.602+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:28:38.602+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:28:38.636+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:28:38.636+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:28:38.809+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:28:38.835+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:28:38.834+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:28:38.856+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:28:38.856+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:28:38.864+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.424 seconds
[2024-08-09T01:29:09.437+0000] {processor.py:161} INFO - Started process (PID=737) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:29:09.439+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:29:09.443+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:29:09.443+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:29:09.561+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:29:09.562+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:29:09.607+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:29:09.608+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:29:09.725+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:29:09.749+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:29:09.749+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:29:09.763+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:29:09.762+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:29:09.771+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.365 seconds
[2024-08-09T01:29:40.259+0000] {processor.py:161} INFO - Started process (PID=739) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:29:40.261+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:29:40.266+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:29:40.265+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:29:40.404+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:29:40.405+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:29:40.453+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:29:40.453+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:29:40.591+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:29:40.616+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:29:40.615+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:29:40.635+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:29:40.634+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:29:40.651+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.430 seconds
[2024-08-09T01:30:11.068+0000] {processor.py:161} INFO - Started process (PID=741) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:30:11.070+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:30:11.094+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:30:11.091+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:30:11.223+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:30:11.223+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:30:11.271+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:30:11.272+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:30:11.391+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:30:11.416+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:30:11.416+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:30:11.453+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:30:11.453+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:30:11.462+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.414 seconds
[2024-08-09T01:30:42.044+0000] {processor.py:161} INFO - Started process (PID=743) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:30:42.046+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:30:42.051+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:30:42.050+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:30:42.194+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:30:42.195+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:30:42.238+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:30:42.238+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:30:42.363+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:30:42.391+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:30:42.390+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:30:42.403+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:30:42.403+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:30:42.412+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.383 seconds
[2024-08-09T01:31:12.944+0000] {processor.py:161} INFO - Started process (PID=745) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:31:12.946+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:31:12.950+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:31:12.950+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:31:13.082+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:31:13.083+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:31:13.119+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:31:13.120+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:31:13.245+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:31:13.269+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:31:13.269+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:31:13.291+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:31:13.290+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:31:13.309+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.390 seconds
[2024-08-09T01:31:43.698+0000] {processor.py:161} INFO - Started process (PID=747) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:31:43.700+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:31:43.704+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:31:43.703+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:31:43.853+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:31:43.853+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:31:43.890+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:31:43.890+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:31:44.052+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:31:44.080+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:31:44.080+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:31:44.103+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:31:44.103+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:31:44.114+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.429 seconds
[2024-08-09T01:32:14.614+0000] {processor.py:161} INFO - Started process (PID=749) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:32:14.617+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:32:14.626+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:32:14.625+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:32:14.779+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:32:14.780+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:32:14.824+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:32:14.825+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:32:14.963+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:32:14.989+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:32:14.989+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:32:15.013+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:32:15.013+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:32:15.022+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.434 seconds
[2024-08-09T01:32:45.499+0000] {processor.py:161} INFO - Started process (PID=751) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:32:45.502+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:32:45.507+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:32:45.506+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:32:45.638+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:32:45.638+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:32:45.675+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:32:45.675+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:32:45.834+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:32:45.860+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:32:45.860+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:32:45.873+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:32:45.873+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:32:45.884+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.398 seconds
[2024-08-09T01:33:16.436+0000] {processor.py:161} INFO - Started process (PID=753) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:33:16.440+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:33:16.446+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:33:16.445+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:33:16.581+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:33:16.581+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:33:16.618+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:33:16.618+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:33:16.737+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:33:16.758+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:33:16.758+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:33:16.771+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:33:16.771+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:33:16.779+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.381 seconds
[2024-08-09T01:33:46.985+0000] {processor.py:161} INFO - Started process (PID=755) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:33:46.987+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:33:46.992+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:33:46.991+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:33:47.145+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:33:47.146+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:33:47.182+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:33:47.182+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:33:47.316+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:33:47.345+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:33:47.345+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:33:47.361+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:33:47.361+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:33:47.371+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.445 seconds
[2024-08-09T01:34:17.690+0000] {processor.py:161} INFO - Started process (PID=757) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:34:17.692+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:34:17.696+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:34:17.696+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:34:17.838+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:34:17.838+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:34:17.876+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:34:17.876+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:34:18.012+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:34:18.034+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:34:18.034+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:34:18.047+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:34:18.047+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:34:18.056+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.378 seconds
[2024-08-09T01:34:48.524+0000] {processor.py:161} INFO - Started process (PID=759) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:34:48.527+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:34:48.531+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:34:48.531+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:34:48.677+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:34:48.677+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:34:48.713+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:34:48.714+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:34:48.840+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:34:48.864+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:34:48.863+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:34:48.876+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:34:48.876+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:34:48.888+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.379 seconds
[2024-08-09T01:35:19.450+0000] {processor.py:161} INFO - Started process (PID=761) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:35:19.454+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:35:19.461+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:35:19.461+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:35:19.698+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:35:19.698+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:35:19.741+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:35:19.741+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:35:19.879+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:35:19.943+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:35:19.942+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:35:19.964+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:35:19.964+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:35:19.977+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.546 seconds
[2024-08-09T01:35:50.502+0000] {processor.py:161} INFO - Started process (PID=763) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:35:50.508+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:35:50.533+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:35:50.531+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:35:50.942+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:35:50.943+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:35:51.052+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:35:51.052+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:35:51.944+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:35:52.223+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:35:52.220+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:35:52.381+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:35:52.381+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:35:52.457+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 1.990 seconds
[2024-08-09T01:36:23.141+0000] {processor.py:161} INFO - Started process (PID=765) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:36:23.147+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:36:23.165+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:36:23.159+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:36:23.615+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:36:23.615+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:36:23.686+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:36:23.686+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:36:23.904+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:36:23.976+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:36:23.976+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:36:24.019+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:36:24.019+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:36:24.037+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.938 seconds
[2024-08-09T01:36:54.612+0000] {processor.py:161} INFO - Started process (PID=767) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:36:54.614+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:36:54.618+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:36:54.617+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:36:54.853+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:36:54.854+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:36:54.946+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:36:54.946+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:36:55.133+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:36:55.224+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:36:55.224+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:36:55.258+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:36:55.258+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:36:55.278+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.679 seconds
[2024-08-09T01:37:25.799+0000] {processor.py:161} INFO - Started process (PID=769) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:37:25.802+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:37:25.808+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:37:25.807+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:37:25.997+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:37:25.997+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:37:26.048+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:37:26.048+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:37:26.189+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:37:26.223+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:37:26.223+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:37:26.238+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:37:26.238+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:37:26.247+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.483 seconds
[2024-08-09T01:37:56.592+0000] {processor.py:161} INFO - Started process (PID=771) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:37:56.594+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:37:56.600+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:37:56.599+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:37:56.785+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:37:56.785+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:37:56.832+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:37:56.832+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:37:57.042+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:37:57.111+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:37:57.109+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:37:57.182+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:37:57.182+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:37:57.218+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.656 seconds
[2024-08-09T01:38:27.732+0000] {processor.py:161} INFO - Started process (PID=773) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:38:27.734+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:38:27.738+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:38:27.738+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:38:27.885+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:38:27.885+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:38:28.011+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:38:28.011+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:38:28.142+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:38:28.184+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:38:28.184+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:38:28.198+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:38:28.198+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:38:28.208+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.492 seconds
[2024-08-09T01:38:58.417+0000] {processor.py:161} INFO - Started process (PID=775) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:38:58.424+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:38:58.429+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:38:58.429+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:38:58.625+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:38:58.626+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:38:58.706+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:38:58.706+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:38:58.853+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:38:58.892+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:38:58.892+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:38:58.907+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:38:58.907+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:38:58.917+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.524 seconds
[2024-08-09T01:39:29.527+0000] {processor.py:161} INFO - Started process (PID=777) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:39:29.529+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:39:29.532+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:39:29.531+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:39:29.637+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:39:29.637+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:39:29.672+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:39:29.673+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:39:29.813+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:39:29.847+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:39:29.847+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:39:29.860+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:39:29.860+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:39:29.868+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.368 seconds
[2024-08-09T01:40:00.343+0000] {processor.py:161} INFO - Started process (PID=779) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:40:00.345+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:40:00.348+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:40:00.348+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:40:00.438+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:40:00.438+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:40:00.477+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:40:00.477+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:40:00.594+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:40:00.638+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:40:00.638+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:40:00.652+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:40:00.652+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:40:00.663+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.330 seconds
[2024-08-09T01:40:30.843+0000] {processor.py:161} INFO - Started process (PID=781) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:40:30.848+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:40:30.861+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:40:30.857+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:40:30.969+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:40:30.970+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:40:31.011+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:40:31.011+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:40:31.159+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:40:31.188+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:40:31.187+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:40:31.201+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:40:31.201+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:40:31.209+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.391 seconds
[2024-08-09T01:41:01.494+0000] {processor.py:161} INFO - Started process (PID=783) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:41:01.496+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:41:01.501+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:41:01.500+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:41:01.611+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:41:01.612+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:41:01.663+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:41:01.663+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:41:01.784+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:41:01.815+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:41:01.814+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:41:01.828+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:41:01.828+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:41:01.840+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.363 seconds
[2024-08-09T01:41:32.277+0000] {processor.py:161} INFO - Started process (PID=785) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:41:32.282+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:41:32.291+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:41:32.290+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:41:32.437+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:41:32.437+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:41:32.475+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:41:32.476+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:41:32.647+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:41:32.697+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:41:32.696+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:41:32.712+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:41:32.711+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:41:32.722+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.461 seconds
[2024-08-09T01:42:03.469+0000] {processor.py:161} INFO - Started process (PID=787) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:42:03.471+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:42:03.474+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:42:03.474+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:42:03.565+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:42:03.566+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:42:03.599+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:42:03.599+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:42:03.738+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:42:03.787+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:42:03.787+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:42:03.812+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:42:03.812+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:42:03.821+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.367 seconds
[2024-08-09T01:42:33.978+0000] {processor.py:161} INFO - Started process (PID=789) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:42:33.979+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:42:33.983+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:42:33.983+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:42:34.071+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:42:34.071+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:42:34.109+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:42:34.110+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:42:34.217+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:42:34.241+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:42:34.241+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:42:34.261+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:42:34.261+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:42:34.271+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.305 seconds
[2024-08-09T01:43:04.663+0000] {processor.py:161} INFO - Started process (PID=791) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:43:04.669+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:43:04.677+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:43:04.676+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:43:04.788+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:43:04.788+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:43:04.834+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:43:04.835+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:43:04.970+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:43:05.008+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:43:05.008+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:43:05.024+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:43:05.023+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:43:05.033+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.387 seconds
[2024-08-09T01:43:35.379+0000] {processor.py:161} INFO - Started process (PID=793) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:43:35.383+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:43:35.387+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:43:35.387+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:43:35.479+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:43:35.479+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:43:35.524+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:43:35.524+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:43:35.700+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:43:35.730+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:43:35.730+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:43:35.743+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:43:35.743+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:43:35.752+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.383 seconds
[2024-08-09T01:44:06.137+0000] {processor.py:161} INFO - Started process (PID=795) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:44:06.141+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:44:06.147+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:44:06.146+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:44:06.245+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:44:06.246+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:44:06.279+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:44:06.279+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:44:06.410+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:44:06.438+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:44:06.438+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:44:06.451+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:44:06.451+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:44:06.459+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.343 seconds
[2024-08-09T01:44:36.676+0000] {processor.py:161} INFO - Started process (PID=797) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:44:36.678+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:44:36.685+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:44:36.683+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:44:36.870+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:44:36.870+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:44:36.929+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:44:36.930+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:44:37.111+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:44:37.167+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:44:37.167+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:44:37.190+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:44:37.190+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:44:37.215+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.561 seconds
[2024-08-09T01:45:07.800+0000] {processor.py:161} INFO - Started process (PID=799) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:45:07.802+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:45:07.807+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:45:07.807+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:45:07.917+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:45:07.917+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:45:07.956+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:45:07.956+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:45:08.096+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:45:08.128+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:45:08.128+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:45:08.142+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:45:08.142+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:45:08.152+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.383 seconds
[2024-08-09T01:45:38.605+0000] {processor.py:161} INFO - Started process (PID=801) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:45:38.608+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:45:38.612+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:45:38.612+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:45:38.708+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:45:38.708+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:45:38.754+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:45:38.754+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:45:38.880+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:45:38.921+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:45:38.921+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:45:38.938+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:45:38.938+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:45:38.947+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.355 seconds
[2024-08-09T01:46:09.309+0000] {processor.py:161} INFO - Started process (PID=803) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:46:09.310+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:46:09.315+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:46:09.314+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:46:09.410+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:46:09.410+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:46:09.452+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:46:09.453+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:46:09.608+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:46:09.669+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:46:09.669+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:46:09.695+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:46:09.695+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:46:09.705+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.411 seconds
[2024-08-09T01:46:39.860+0000] {processor.py:161} INFO - Started process (PID=805) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:46:39.862+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:46:39.873+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:46:39.870+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:46:40.024+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:46:40.024+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:46:40.089+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:46:40.089+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:46:40.218+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:46:40.256+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:46:40.255+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:46:40.275+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:46:40.275+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:46:40.288+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.453 seconds
[2024-08-09T01:47:10.517+0000] {processor.py:161} INFO - Started process (PID=807) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:47:10.528+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:47:10.532+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:47:10.531+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:47:10.616+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:47:10.616+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:47:10.661+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:47:10.662+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:47:10.778+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:47:10.824+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:47:10.824+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:47:10.840+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:47:10.840+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:47:10.848+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.371 seconds
[2024-08-09T01:47:41.077+0000] {processor.py:161} INFO - Started process (PID=809) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:47:41.079+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:47:41.083+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:47:41.083+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:47:41.186+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:47:41.187+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:47:41.232+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:47:41.232+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:47:41.362+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:47:41.421+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:47:41.420+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:47:41.444+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:47:41.444+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:47:41.457+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.404 seconds
[2024-08-09T01:48:11.650+0000] {processor.py:161} INFO - Started process (PID=811) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:48:11.653+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:48:11.661+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:48:11.659+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:48:11.756+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:48:11.756+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:48:11.789+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:48:11.789+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:48:11.898+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:48:11.940+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:48:11.940+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:48:11.953+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:48:11.953+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:48:11.961+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.327 seconds
[2024-08-09T01:48:42.196+0000] {processor.py:161} INFO - Started process (PID=813) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:48:42.205+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:48:42.219+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:48:42.218+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:48:42.494+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:48:42.494+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:48:42.535+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:48:42.535+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:48:42.688+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:48:42.716+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:48:42.716+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:48:42.745+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:48:42.744+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:48:42.755+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.617 seconds
[2024-08-09T01:49:13.141+0000] {processor.py:161} INFO - Started process (PID=815) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:49:13.144+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:49:13.148+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:49:13.147+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:49:13.248+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:49:13.249+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:49:13.284+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:49:13.284+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:49:13.405+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:49:13.442+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:49:13.442+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:49:13.456+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:49:13.456+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:49:13.465+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.351 seconds
[2024-08-09T01:49:43.810+0000] {processor.py:161} INFO - Started process (PID=817) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:49:43.812+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:49:43.817+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:49:43.816+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:49:43.931+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:49:43.932+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:49:43.966+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:49:43.966+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:49:44.085+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:49:44.115+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:49:44.115+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:49:44.129+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:49:44.128+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:49:44.137+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.344 seconds
[2024-08-09T01:50:14.888+0000] {processor.py:161} INFO - Started process (PID=819) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:50:14.891+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:50:14.897+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:50:14.896+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:50:15.049+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:50:15.049+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:50:15.089+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:50:15.089+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:50:15.210+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:50:15.237+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:50:15.237+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:50:15.251+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:50:15.251+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:50:15.260+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.408 seconds
[2024-08-09T01:50:45.462+0000] {processor.py:161} INFO - Started process (PID=821) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:50:45.465+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:50:45.469+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:50:45.468+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:50:45.574+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:50:45.575+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:50:45.611+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:50:45.611+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:50:45.729+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:50:45.753+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:50:45.752+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:50:45.774+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:50:45.774+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:50:45.783+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.334 seconds
[2024-08-09T01:51:16.074+0000] {processor.py:161} INFO - Started process (PID=823) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:51:16.077+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:51:16.081+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:51:16.080+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:51:16.202+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:51:16.202+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:51:16.236+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:51:16.236+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:51:16.369+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:51:16.392+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:51:16.392+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:51:16.406+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:51:16.406+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:51:16.416+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.364 seconds
[2024-08-09T01:51:46.550+0000] {processor.py:161} INFO - Started process (PID=825) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:51:46.552+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:51:46.557+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:51:46.556+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:51:46.682+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:51:46.682+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:51:46.716+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:51:46.716+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:51:46.836+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:51:46.860+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:51:46.860+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:51:46.886+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:51:46.886+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:51:46.895+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.361 seconds
[2024-08-09T01:52:17.097+0000] {processor.py:161} INFO - Started process (PID=827) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:52:17.101+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:52:17.108+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:52:17.107+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:52:17.212+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:52:17.212+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:52:17.254+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:52:17.255+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:52:17.375+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:52:17.396+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:52:17.396+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:52:17.410+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:52:17.410+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:52:17.418+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.343 seconds
[2024-08-09T01:52:47.601+0000] {processor.py:161} INFO - Started process (PID=829) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:52:47.603+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:52:47.608+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:52:47.607+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:52:47.731+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:52:47.731+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:52:47.771+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:52:47.772+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:52:47.883+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:52:47.920+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:52:47.919+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:52:47.933+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:52:47.933+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:52:47.943+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.356 seconds
[2024-08-09T01:53:18.168+0000] {processor.py:161} INFO - Started process (PID=831) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:53:18.171+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:53:18.175+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:53:18.175+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:53:18.284+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:53:18.284+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:53:18.316+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:53:18.316+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:53:18.436+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:53:18.458+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:53:18.458+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:53:18.480+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:53:18.480+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:53:18.489+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.355 seconds
[2024-08-09T01:53:48.706+0000] {processor.py:161} INFO - Started process (PID=833) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:53:48.708+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:53:48.713+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:53:48.712+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:53:48.816+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:53:48.817+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:53:48.851+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:53:48.851+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:53:48.974+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:53:49.066+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:53:49.066+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:53:49.081+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:53:49.081+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:53:49.090+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.422 seconds
[2024-08-09T01:54:19.610+0000] {processor.py:161} INFO - Started process (PID=835) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:54:19.612+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:54:19.617+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:54:19.616+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:54:19.729+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:54:19.729+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:54:19.775+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:54:19.775+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:54:19.910+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:54:19.948+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:54:19.948+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:54:19.961+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:54:19.961+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:54:19.969+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.374 seconds
[2024-08-09T01:54:50.481+0000] {processor.py:161} INFO - Started process (PID=837) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:54:50.490+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:54:50.494+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:54:50.494+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:54:50.607+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:54:50.607+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:54:50.644+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:54:50.644+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:54:50.779+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:54:50.820+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:54:50.819+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:54:50.833+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:54:50.833+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:54:50.842+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.392 seconds
[2024-08-09T01:55:21.271+0000] {processor.py:161} INFO - Started process (PID=839) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:55:21.273+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:55:21.279+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:55:21.278+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:55:21.402+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:55:21.402+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:55:21.453+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:55:21.454+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:55:21.582+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:55:21.610+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:55:21.610+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:55:21.625+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:55:21.625+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:55:21.638+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.392 seconds
[2024-08-09T01:55:51.991+0000] {processor.py:161} INFO - Started process (PID=841) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:55:51.992+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:55:51.997+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:55:51.997+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:55:52.109+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:55:52.109+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:55:52.155+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:55:52.156+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:55:52.273+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:55:52.314+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:55:52.314+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:55:52.328+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:55:52.328+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:55:52.336+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.359 seconds
[2024-08-09T01:56:22.446+0000] {processor.py:161} INFO - Started process (PID=843) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:56:22.452+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:56:22.468+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:56:22.467+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:56:22.572+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:56:22.572+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:56:22.606+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:56:22.606+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:56:22.732+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:56:22.756+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:56:22.756+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:56:22.770+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:56:22.770+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:56:22.779+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.359 seconds
[2024-08-09T01:56:53.485+0000] {processor.py:161} INFO - Started process (PID=845) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:56:53.486+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:56:53.502+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:56:53.502+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:56:53.647+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:56:53.647+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:56:53.686+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:56:53.686+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:56:53.823+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:56:53.866+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:56:53.866+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:56:53.880+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:56:53.880+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:56:53.892+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.418 seconds
[2024-08-09T01:57:24.262+0000] {processor.py:161} INFO - Started process (PID=847) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:57:24.263+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:57:24.268+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:57:24.267+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:57:24.378+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:57:24.379+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:57:24.412+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:57:24.412+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:57:24.536+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:57:24.570+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:57:24.570+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:57:24.583+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:57:24.583+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:57:24.592+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.361 seconds
[2024-08-09T01:57:54.743+0000] {processor.py:161} INFO - Started process (PID=849) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:57:54.744+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:57:54.749+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:57:54.748+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:57:54.862+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:57:54.863+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:57:54.903+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:57:54.904+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:57:55.037+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:57:55.112+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:57:55.112+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:57:55.126+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:57:55.126+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:57:55.135+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.406 seconds
[2024-08-09T01:58:25.409+0000] {processor.py:161} INFO - Started process (PID=851) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:58:25.411+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:58:25.416+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:58:25.415+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:58:25.525+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:58:25.526+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:58:25.570+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:58:25.571+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:58:25.691+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:58:25.714+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:58:25.714+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:58:25.731+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:58:25.731+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:58:25.745+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.350 seconds
[2024-08-09T01:58:56.185+0000] {processor.py:161} INFO - Started process (PID=853) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:58:56.189+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:58:56.199+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:58:56.198+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:58:56.357+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:58:56.358+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:58:56.401+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:58:56.401+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:58:56.595+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:58:56.630+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:58:56.630+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:58:56.652+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:58:56.652+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:58:56.673+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.579 seconds
[2024-08-09T01:59:27.030+0000] {processor.py:161} INFO - Started process (PID=855) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:59:27.031+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:59:27.038+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:59:27.037+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:59:27.116+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:59:27.116+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:59:27.139+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:59:27.139+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:59:27.245+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:59:27.262+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:59:27.262+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:59:27.273+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:59:27.273+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:59:27.280+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.268 seconds
[2024-08-09T01:59:57.753+0000] {processor.py:161} INFO - Started process (PID=857) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:59:57.755+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T01:59:57.761+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:59:57.760+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:59:57.886+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:59:57.887+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:59:57.920+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T01:59:57.920+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T01:59:58.045+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T01:59:58.078+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:59:58.078+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T01:59:58.093+0000] {logging_mixin.py:188} INFO - [2024-08-09T01:59:58.093+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T01:59:58.103+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.377 seconds
[2024-08-09T02:00:28.540+0000] {processor.py:161} INFO - Started process (PID=859) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T02:00:28.541+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T02:00:28.545+0000] {logging_mixin.py:188} INFO - [2024-08-09T02:00:28.545+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T02:00:28.640+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T02:00:28.640+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T02:00:28.679+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T02:00:28.679+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T02:00:28.791+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T02:00:28.827+0000] {logging_mixin.py:188} INFO - [2024-08-09T02:00:28.827+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T02:00:28.840+0000] {logging_mixin.py:188} INFO - [2024-08-09T02:00:28.839+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T02:00:28.848+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.321 seconds
[2024-08-09T02:00:59.265+0000] {processor.py:161} INFO - Started process (PID=861) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T02:00:59.266+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T02:00:59.270+0000] {logging_mixin.py:188} INFO - [2024-08-09T02:00:59.270+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T02:00:59.380+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T02:00:59.381+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T02:00:59.417+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T02:00:59.417+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T02:00:59.544+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T02:00:59.571+0000] {logging_mixin.py:188} INFO - [2024-08-09T02:00:59.571+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T02:00:59.593+0000] {logging_mixin.py:188} INFO - [2024-08-09T02:00:59.593+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T02:00:59.603+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.366 seconds
[2024-08-09T02:01:29.970+0000] {processor.py:161} INFO - Started process (PID=863) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T02:01:29.971+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T02:01:29.976+0000] {logging_mixin.py:188} INFO - [2024-08-09T02:01:29.975+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T02:01:30.085+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T02:01:30.086+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T02:01:30.121+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T02:01:30.121+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T02:01:30.245+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T02:01:30.271+0000] {logging_mixin.py:188} INFO - [2024-08-09T02:01:30.271+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T02:01:30.284+0000] {logging_mixin.py:188} INFO - [2024-08-09T02:01:30.284+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T02:01:30.293+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.337 seconds
[2024-08-09T02:02:00.746+0000] {processor.py:161} INFO - Started process (PID=865) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T02:02:00.750+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T02:02:00.826+0000] {logging_mixin.py:188} INFO - [2024-08-09T02:02:00.822+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T02:02:01.008+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T02:02:01.008+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T02:02:01.073+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T02:02:01.074+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T02:02:01.349+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T02:02:01.422+0000] {logging_mixin.py:188} INFO - [2024-08-09T02:02:01.422+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T02:02:01.440+0000] {logging_mixin.py:188} INFO - [2024-08-09T02:02:01.440+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T02:02:01.449+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.914 seconds
[2024-08-09T02:02:31.982+0000] {processor.py:161} INFO - Started process (PID=867) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T02:02:31.984+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T02:02:31.989+0000] {logging_mixin.py:188} INFO - [2024-08-09T02:02:31.988+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T02:02:32.099+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T02:02:32.100+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T02:02:32.133+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T02:02:32.134+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T02:02:32.300+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T02:02:32.346+0000] {logging_mixin.py:188} INFO - [2024-08-09T02:02:32.346+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T02:02:32.361+0000] {logging_mixin.py:188} INFO - [2024-08-09T02:02:32.361+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T02:02:32.372+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.401 seconds
[2024-08-09T02:03:02.784+0000] {processor.py:161} INFO - Started process (PID=869) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T02:03:02.786+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T02:03:02.789+0000] {logging_mixin.py:188} INFO - [2024-08-09T02:03:02.788+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T02:03:02.897+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T02:03:02.897+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T02:03:02.946+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T02:03:02.947+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T02:03:03.283+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T02:03:03.356+0000] {logging_mixin.py:188} INFO - [2024-08-09T02:03:03.356+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T02:03:03.378+0000] {logging_mixin.py:188} INFO - [2024-08-09T02:03:03.378+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T02:03:03.404+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.629 seconds
[2024-08-09T02:03:33.929+0000] {processor.py:161} INFO - Started process (PID=871) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T02:03:33.932+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T02:03:33.939+0000] {logging_mixin.py:188} INFO - [2024-08-09T02:03:33.938+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T02:03:34.050+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T02:03:34.050+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T02:03:34.082+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T02:03:34.083+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T02:03:34.233+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T02:03:34.275+0000] {logging_mixin.py:188} INFO - [2024-08-09T02:03:34.275+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T02:03:34.289+0000] {logging_mixin.py:188} INFO - [2024-08-09T02:03:34.289+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T02:03:34.299+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.397 seconds
[2024-08-09T02:04:04.715+0000] {processor.py:161} INFO - Started process (PID=873) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T02:04:04.717+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T02:04:04.720+0000] {logging_mixin.py:188} INFO - [2024-08-09T02:04:04.719+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T02:04:04.811+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T02:04:04.811+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T02:04:04.846+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T02:04:04.846+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T02:04:04.971+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T02:04:05.010+0000] {logging_mixin.py:188} INFO - [2024-08-09T02:04:05.010+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T02:04:05.026+0000] {logging_mixin.py:188} INFO - [2024-08-09T02:04:05.026+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T02:04:05.035+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.345 seconds
[2024-08-09T02:04:35.416+0000] {processor.py:161} INFO - Started process (PID=875) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T02:04:35.417+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T02:04:35.421+0000] {logging_mixin.py:188} INFO - [2024-08-09T02:04:35.420+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T02:04:35.518+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T02:04:35.518+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T02:04:35.557+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T02:04:35.557+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T02:04:35.754+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T02:04:35.795+0000] {logging_mixin.py:188} INFO - [2024-08-09T02:04:35.794+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T02:04:35.811+0000] {logging_mixin.py:188} INFO - [2024-08-09T02:04:35.811+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T02:04:35.822+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.419 seconds
[2024-08-09T02:05:06.335+0000] {processor.py:161} INFO - Started process (PID=877) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T02:05:06.337+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T02:05:06.348+0000] {logging_mixin.py:188} INFO - [2024-08-09T02:05:06.347+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T02:05:06.477+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T02:05:06.478+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T02:05:06.519+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T02:05:06.519+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T02:05:06.650+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T02:05:06.688+0000] {logging_mixin.py:188} INFO - [2024-08-09T02:05:06.688+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T02:05:06.704+0000] {logging_mixin.py:188} INFO - [2024-08-09T02:05:06.704+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T02:05:06.725+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.433 seconds
[2024-08-09T02:05:37.395+0000] {processor.py:161} INFO - Started process (PID=879) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T02:05:37.397+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T02:05:37.401+0000] {logging_mixin.py:188} INFO - [2024-08-09T02:05:37.401+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T02:05:37.504+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T02:05:37.505+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T02:05:37.539+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T02:05:37.540+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T02:05:37.693+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T02:05:37.776+0000] {logging_mixin.py:188} INFO - [2024-08-09T02:05:37.776+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T02:05:37.799+0000] {logging_mixin.py:188} INFO - [2024-08-09T02:05:37.799+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T02:05:37.811+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.427 seconds
[2024-08-09T02:06:08.230+0000] {processor.py:161} INFO - Started process (PID=881) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T02:06:08.233+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T02:06:08.237+0000] {logging_mixin.py:188} INFO - [2024-08-09T02:06:08.236+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T02:06:08.332+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T02:06:08.332+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T02:06:08.373+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T02:06:08.373+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T02:06:08.507+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T02:06:08.536+0000] {logging_mixin.py:188} INFO - [2024-08-09T02:06:08.536+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T02:06:08.569+0000] {logging_mixin.py:188} INFO - [2024-08-09T02:06:08.569+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T02:06:08.578+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.360 seconds
[2024-08-09T02:06:39.066+0000] {processor.py:161} INFO - Started process (PID=883) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T02:06:39.068+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T02:06:39.072+0000] {logging_mixin.py:188} INFO - [2024-08-09T02:06:39.072+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T02:06:39.167+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T02:06:39.168+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T02:06:39.211+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T02:06:39.212+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T02:06:39.523+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T02:06:39.578+0000] {logging_mixin.py:188} INFO - [2024-08-09T02:06:39.578+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T02:06:39.595+0000] {logging_mixin.py:188} INFO - [2024-08-09T02:06:39.595+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T02:06:39.606+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.553 seconds
[2024-08-09T02:07:10.303+0000] {processor.py:161} INFO - Started process (PID=885) to work on /opt/airflow/dags/reddit_dag.py
[2024-08-09T02:07:10.311+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2024-08-09T02:07:10.330+0000] {logging_mixin.py:188} INFO - [2024-08-09T02:07:10.326+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2024-08-09T02:07:10.447+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T02:07:10.448+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T02:07:10.483+0000] {logging_mixin.py:188} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.1 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/__main__.py", line 58, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/cli.py", line 114, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 58, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/daemon_utils.py", line 85, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 61, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/cli/commands/scheduler_command.py", line 49, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 402, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/job.py", line 431, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/jobs/scheduler_job_runner.py", line 842, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 168, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 241, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 476, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 619, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/manager.py", line 1087, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 238, in start
    process.start()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.11/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.11/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 833, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 797, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 152, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 559, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 318, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 381, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    from etls.reddit_etl import connect_reddit,transform_data,load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 5, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.11/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2024-08-09T02:07:10.483+0000] {logging_mixin.py:188} WARNING - AttributeError: _ARRAY_API not found
[2024-08-09T02:07:10.617+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2024-08-09T02:07:10.658+0000] {logging_mixin.py:188} INFO - [2024-08-09T02:07:10.658+0000] {dag.py:3089} INFO - Sync 1 DAGs
[2024-08-09T02:07:10.675+0000] {logging_mixin.py:188} INFO - [2024-08-09T02:07:10.675+0000] {dag.py:3947} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-08-09 00:00:00+00:00, run_after=2024-08-10 00:00:00+00:00
[2024-08-09T02:07:10.691+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.404 seconds
